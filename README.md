n_gram_app helps predict sequence from William Blake's Poems, the data for which was obtained from gutenberg's
blake-poems.txt

Steps to the UI:
1. Run n_gram_app.py
2. Open web browser on http://127.0.0.1:5000/
3. Enter inputs

'''# LLMs

This repository covers building, training and evaluating large language models. We start from simple n-gram models and escalate to RNNs, attention based models, transformers.

## n-gram Models
In the first few commits, we covered n-gram models which use text corpus to build Probability Distribution Functions (PDF). These PDFs are used to predict the next word based on the sequence provided to the model. These sequences vary as 'n' in the n-gram model changes.

During the testing and evaluation phase, we compare results of uni-gram, bi-gram and tri-gram models

'''

