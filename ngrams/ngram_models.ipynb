{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "\n",
    "# Choose a text from the Gutenberg corpus\n",
    "text_id = 'shakespeare-macbeth.txt'\n",
    "raw_text = gutenberg.raw(text_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = gutenberg.fileids()\n",
    "text = [gutenberg.raw(fileid) for fileid in gutenberg.fileids()]\n",
    "\n",
    "file_text = dict(zip(files, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning and preprocessing data\n",
    "#text cleaning - remove non-alphanumeric/special characters, removing stop words, lower case\n",
    "\n",
    "def preprocess(text):\n",
    "    #Tokenize lowercase, and remove stop words\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    \n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "#Bishal Agarwal - can avoid removing stopwords. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Macbeth by William Shakespeare 16\n",
      "['tragedie', 'macbeth', 'william', 'shakespeare', 'actus']\n"
     ]
    }
   ],
   "source": [
    "#testing on one file-text pair\n",
    "raw_text_pre = preprocess(raw_text)\n",
    "print(raw_text[:50])\n",
    "print(raw_text_pre[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this for rhe entire file_text dictionary and generate tokens\n",
    "for key, value in file_text.items():\n",
    "    file_text[key] = preprocess(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tragedie',\n",
       " 'macbeth',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'actus',\n",
       " 'primus',\n",
       " 'scoena',\n",
       " 'prima',\n",
       " 'thunder',\n",
       " 'lightning',\n",
       " 'enter',\n",
       " 'three',\n",
       " 'witch',\n",
       " 'shall',\n",
       " 'three',\n",
       " 'meet',\n",
       " 'againe',\n",
       " 'thunder',\n",
       " 'lightning',\n",
       " 'raine',\n",
       " 'done',\n",
       " 'battaile',\n",
       " 'lost',\n",
       " 'wonne',\n",
       " 'ere',\n",
       " 'set',\n",
       " 'sunne',\n",
       " 'place',\n",
       " 'vpon',\n",
       " 'heath',\n",
       " 'meet',\n",
       " 'macbeth',\n",
       " 'come',\n",
       " 'padock',\n",
       " 'call',\n",
       " 'anon',\n",
       " 'faire',\n",
       " 'foule',\n",
       " 'foule',\n",
       " 'faire',\n",
       " 'houer',\n",
       " 'fogge',\n",
       " 'filthie',\n",
       " 'ayre',\n",
       " 'exeunt',\n",
       " 'scena',\n",
       " 'secunda',\n",
       " 'alarum',\n",
       " 'within',\n",
       " 'enter',\n",
       " 'king',\n",
       " 'malcome',\n",
       " 'donalbaine',\n",
       " 'lenox',\n",
       " 'attendant',\n",
       " 'meeting',\n",
       " 'bleeding',\n",
       " 'captaine',\n",
       " 'king',\n",
       " 'bloody',\n",
       " 'man',\n",
       " 'report',\n",
       " 'seemeth',\n",
       " 'plight',\n",
       " 'reuolt',\n",
       " 'newest',\n",
       " 'state',\n",
       " 'mal',\n",
       " 'serieant',\n",
       " 'like',\n",
       " 'good',\n",
       " 'hardie',\n",
       " 'souldier',\n",
       " 'fought',\n",
       " 'captiuitie',\n",
       " 'haile',\n",
       " 'braue',\n",
       " 'friend',\n",
       " 'say',\n",
       " 'king',\n",
       " 'knowledge',\n",
       " 'broyle',\n",
       " 'thou',\n",
       " 'didst',\n",
       " 'leaue',\n",
       " 'cap',\n",
       " 'doubtfull',\n",
       " 'stood',\n",
       " 'two',\n",
       " 'spent',\n",
       " 'swimmer',\n",
       " 'doe',\n",
       " 'cling',\n",
       " 'together',\n",
       " 'choake',\n",
       " 'art',\n",
       " 'mercilesse',\n",
       " 'macdonwald',\n",
       " 'worthie',\n",
       " 'rebell',\n",
       " 'multiplying',\n",
       " 'villanies',\n",
       " 'nature',\n",
       " 'doe',\n",
       " 'swarme',\n",
       " 'vpon',\n",
       " 'westerne',\n",
       " 'isle',\n",
       " 'kernes',\n",
       " 'gallowgrosses',\n",
       " 'supply',\n",
       " 'fortune',\n",
       " 'damned',\n",
       " 'quarry',\n",
       " 'smiling',\n",
       " 'shew',\n",
       " 'like',\n",
       " 'rebells',\n",
       " 'whore',\n",
       " 'weake',\n",
       " 'braue',\n",
       " 'macbeth',\n",
       " 'well',\n",
       " 'hee',\n",
       " 'deserues',\n",
       " 'name',\n",
       " 'disdayning',\n",
       " 'fortune',\n",
       " 'brandisht',\n",
       " 'steele',\n",
       " 'smoak',\n",
       " 'bloody',\n",
       " 'execution',\n",
       " 'like',\n",
       " 'valour',\n",
       " 'minion',\n",
       " 'caru',\n",
       " 'passage',\n",
       " 'till',\n",
       " 'hee',\n",
       " 'fac',\n",
       " 'slaue',\n",
       " 'neu',\n",
       " 'r',\n",
       " 'shooke',\n",
       " 'hand',\n",
       " 'bad',\n",
       " 'farwell',\n",
       " 'till',\n",
       " 'vnseam',\n",
       " 'naue',\n",
       " 'toth',\n",
       " 'chop',\n",
       " 'fix',\n",
       " 'head',\n",
       " 'vpon',\n",
       " 'battlement',\n",
       " 'king',\n",
       " 'valiant',\n",
       " 'cousin',\n",
       " 'worthy',\n",
       " 'gentleman',\n",
       " 'cap',\n",
       " 'whence',\n",
       " 'sunne',\n",
       " 'reflection',\n",
       " 'shipwracking',\n",
       " 'stormes',\n",
       " 'direfull',\n",
       " 'thunder',\n",
       " 'spring',\n",
       " 'whence',\n",
       " 'comfort',\n",
       " 'seem',\n",
       " 'come',\n",
       " 'discomfort',\n",
       " 'swell',\n",
       " 'marke',\n",
       " 'king',\n",
       " 'scotland',\n",
       " 'marke',\n",
       " 'sooner',\n",
       " 'iustice',\n",
       " 'valour',\n",
       " 'arm',\n",
       " 'compell',\n",
       " 'skipping',\n",
       " 'kernes',\n",
       " 'trust',\n",
       " 'heeles',\n",
       " 'norweyan',\n",
       " 'lord',\n",
       " 'surueying',\n",
       " 'vantage',\n",
       " 'furbusht',\n",
       " 'armes',\n",
       " 'new',\n",
       " 'supplyes',\n",
       " 'men',\n",
       " 'began',\n",
       " 'fresh',\n",
       " 'assault',\n",
       " 'king',\n",
       " 'dismay',\n",
       " 'captaines',\n",
       " 'macbeth',\n",
       " 'banquoh',\n",
       " 'cap',\n",
       " 'yes',\n",
       " 'sparrowes',\n",
       " 'eagle',\n",
       " 'hare',\n",
       " 'lyon',\n",
       " 'say',\n",
       " 'sooth',\n",
       " 'must',\n",
       " 'report',\n",
       " 'cannon',\n",
       " 'double',\n",
       " 'crack',\n",
       " 'doubly',\n",
       " 'redoubled',\n",
       " 'stroakes',\n",
       " 'vpon',\n",
       " 'foe',\n",
       " 'except',\n",
       " 'meant',\n",
       " 'bathe',\n",
       " 'reeking',\n",
       " 'wound',\n",
       " 'memorize',\n",
       " 'another',\n",
       " 'golgotha',\n",
       " 'tell',\n",
       " 'faint',\n",
       " 'gash',\n",
       " 'cry',\n",
       " 'helpe',\n",
       " 'king',\n",
       " 'well',\n",
       " 'thy',\n",
       " 'word',\n",
       " 'become',\n",
       " 'thee',\n",
       " 'thy',\n",
       " 'wound',\n",
       " 'smack',\n",
       " 'honor',\n",
       " 'goe',\n",
       " 'get',\n",
       " 'surgeon',\n",
       " 'enter',\n",
       " 'rosse',\n",
       " 'angus',\n",
       " 'come',\n",
       " 'mal',\n",
       " 'worthy',\n",
       " 'thane',\n",
       " 'rosse',\n",
       " 'lenox',\n",
       " 'haste',\n",
       " 'lookes',\n",
       " 'eye',\n",
       " 'looke',\n",
       " 'seemes',\n",
       " 'speake',\n",
       " 'thing',\n",
       " 'strange',\n",
       " 'rosse',\n",
       " 'god',\n",
       " 'saue',\n",
       " 'king',\n",
       " 'king',\n",
       " 'whence',\n",
       " 'thou',\n",
       " 'worthy',\n",
       " 'thane',\n",
       " 'rosse',\n",
       " 'fiffe',\n",
       " 'great',\n",
       " 'king',\n",
       " 'norweyan',\n",
       " 'banner',\n",
       " 'flowt',\n",
       " 'skie',\n",
       " 'fanne',\n",
       " 'people',\n",
       " 'cold',\n",
       " 'norway',\n",
       " 'himselfe',\n",
       " 'terrible',\n",
       " 'number',\n",
       " 'assisted',\n",
       " 'disloyall',\n",
       " 'traytor',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'began',\n",
       " 'dismall',\n",
       " 'conflict',\n",
       " 'till',\n",
       " 'bellona',\n",
       " 'bridegroome',\n",
       " 'lapt',\n",
       " 'proofe',\n",
       " 'confronted',\n",
       " 'point',\n",
       " 'point',\n",
       " 'rebellious',\n",
       " 'arme',\n",
       " 'arme',\n",
       " 'curbing',\n",
       " 'lauish',\n",
       " 'spirit',\n",
       " 'conclude',\n",
       " 'victorie',\n",
       " 'fell',\n",
       " 'v',\n",
       " 'king',\n",
       " 'great',\n",
       " 'happinesse',\n",
       " 'rosse',\n",
       " 'sweno',\n",
       " 'norwayes',\n",
       " 'king',\n",
       " 'craues',\n",
       " 'composition',\n",
       " 'would',\n",
       " 'deigne',\n",
       " 'buriall',\n",
       " 'men',\n",
       " 'till',\n",
       " 'disbursed',\n",
       " 'saint',\n",
       " 'colmes',\n",
       " 'ynch',\n",
       " 'ten',\n",
       " 'thousand',\n",
       " 'dollar',\n",
       " 'generall',\n",
       " 'vse',\n",
       " 'king',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'shall',\n",
       " 'deceiue',\n",
       " 'bosome',\n",
       " 'interest',\n",
       " 'goe',\n",
       " 'pronounce',\n",
       " 'present',\n",
       " 'death',\n",
       " 'former',\n",
       " 'title',\n",
       " 'greet',\n",
       " 'macbeth',\n",
       " 'rosse',\n",
       " 'ile',\n",
       " 'see',\n",
       " 'done',\n",
       " 'king',\n",
       " 'hath',\n",
       " 'lost',\n",
       " 'noble',\n",
       " 'macbeth',\n",
       " 'hath',\n",
       " 'wonne',\n",
       " 'exeunt',\n",
       " 'scena',\n",
       " 'tertia',\n",
       " 'thunder',\n",
       " 'enter',\n",
       " 'three',\n",
       " 'witch',\n",
       " 'hast',\n",
       " 'thou',\n",
       " 'beene',\n",
       " 'sister',\n",
       " 'killing',\n",
       " 'swine',\n",
       " 'sister',\n",
       " 'thou',\n",
       " 'saylors',\n",
       " 'wife',\n",
       " 'chestnut',\n",
       " 'lappe',\n",
       " 'mouncht',\n",
       " 'mouncht',\n",
       " 'mouncht',\n",
       " 'giue',\n",
       " 'quoth',\n",
       " 'aroynt',\n",
       " 'thee',\n",
       " 'witch',\n",
       " 'ronyon',\n",
       " 'cryes',\n",
       " 'husband',\n",
       " 'aleppo',\n",
       " 'gone',\n",
       " 'master',\n",
       " 'tiger',\n",
       " 'syue',\n",
       " 'ile',\n",
       " 'thither',\n",
       " 'sayle',\n",
       " 'like',\n",
       " 'rat',\n",
       " 'without',\n",
       " 'tayle',\n",
       " 'ile',\n",
       " 'doe',\n",
       " 'ile',\n",
       " 'doe',\n",
       " 'ile',\n",
       " 'doe',\n",
       " 'ile',\n",
       " 'giue',\n",
       " 'thee',\n",
       " 'winde',\n",
       " 'kinde',\n",
       " 'another',\n",
       " 'selfe',\n",
       " 'haue',\n",
       " 'port',\n",
       " 'blow',\n",
       " 'quarter',\n",
       " 'know',\n",
       " 'card',\n",
       " 'ile',\n",
       " 'dreyne',\n",
       " 'drie',\n",
       " 'hay',\n",
       " 'sleepe',\n",
       " 'shall',\n",
       " 'neyther',\n",
       " 'night',\n",
       " 'day',\n",
       " 'hang',\n",
       " 'vpon',\n",
       " 'lid',\n",
       " 'shall',\n",
       " 'liue',\n",
       " 'man',\n",
       " 'forbid',\n",
       " 'wearie',\n",
       " 'nine',\n",
       " 'time',\n",
       " 'nine',\n",
       " 'shall',\n",
       " 'dwindle',\n",
       " 'peake',\n",
       " 'pine',\n",
       " 'though',\n",
       " 'barke',\n",
       " 'lost',\n",
       " 'yet',\n",
       " 'shall',\n",
       " 'looke',\n",
       " 'haue',\n",
       " 'shew',\n",
       " 'shew',\n",
       " 'haue',\n",
       " 'pilot',\n",
       " 'thumbe',\n",
       " 'wrackt',\n",
       " 'homeward',\n",
       " 'come',\n",
       " 'drum',\n",
       " 'within',\n",
       " 'drumme',\n",
       " 'drumme',\n",
       " 'macbeth',\n",
       " 'doth',\n",
       " 'come',\n",
       " 'weyward',\n",
       " 'sister',\n",
       " 'hand',\n",
       " 'hand',\n",
       " 'poster',\n",
       " 'sea',\n",
       " 'land',\n",
       " 'thus',\n",
       " 'doe',\n",
       " 'goe',\n",
       " 'thrice',\n",
       " 'thine',\n",
       " 'thrice',\n",
       " 'mine',\n",
       " 'thrice',\n",
       " 'againe',\n",
       " 'make',\n",
       " 'vp',\n",
       " 'nine',\n",
       " 'peace',\n",
       " 'charme',\n",
       " 'wound',\n",
       " 'vp',\n",
       " 'enter',\n",
       " 'macbeth',\n",
       " 'banquo',\n",
       " 'macb',\n",
       " 'foule',\n",
       " 'faire',\n",
       " 'day',\n",
       " 'haue',\n",
       " 'seene',\n",
       " 'banquo',\n",
       " 'farre',\n",
       " 'call',\n",
       " 'soris',\n",
       " 'wither',\n",
       " 'wilde',\n",
       " 'attyre',\n",
       " 'looke',\n",
       " 'like',\n",
       " 'th',\n",
       " 'inhabitant',\n",
       " 'earth',\n",
       " 'yet',\n",
       " 'liue',\n",
       " 'aught',\n",
       " 'man',\n",
       " 'may',\n",
       " 'question',\n",
       " 'seeme',\n",
       " 'vnderstand',\n",
       " 'choppie',\n",
       " 'finger',\n",
       " 'laying',\n",
       " 'vpon',\n",
       " 'skinnie',\n",
       " 'lip',\n",
       " 'woman',\n",
       " 'yet',\n",
       " 'beard',\n",
       " 'forbid',\n",
       " 'interprete',\n",
       " 'mac',\n",
       " 'speake',\n",
       " 'haile',\n",
       " 'macbeth',\n",
       " 'haile',\n",
       " 'thee',\n",
       " 'thane',\n",
       " 'glamis',\n",
       " 'haile',\n",
       " 'macbeth',\n",
       " 'haile',\n",
       " 'thee',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'haile',\n",
       " 'macbeth',\n",
       " 'shalt',\n",
       " 'king',\n",
       " 'hereafter',\n",
       " 'banq',\n",
       " 'good',\n",
       " 'sir',\n",
       " 'doe',\n",
       " 'start',\n",
       " 'seeme',\n",
       " 'feare',\n",
       " 'thing',\n",
       " 'doe',\n",
       " 'sound',\n",
       " 'faire',\n",
       " 'name',\n",
       " 'truth',\n",
       " 'ye',\n",
       " 'fantasticall',\n",
       " 'indeed',\n",
       " 'outwardly',\n",
       " 'ye',\n",
       " 'shew',\n",
       " 'noble',\n",
       " 'partner',\n",
       " 'greet',\n",
       " 'present',\n",
       " 'grace',\n",
       " 'great',\n",
       " 'prediction',\n",
       " 'noble',\n",
       " 'hauing',\n",
       " 'royall',\n",
       " 'hope',\n",
       " 'seemes',\n",
       " 'wrapt',\n",
       " 'withall',\n",
       " 'speake',\n",
       " 'looke',\n",
       " 'seedes',\n",
       " 'time',\n",
       " 'say',\n",
       " 'graine',\n",
       " 'grow',\n",
       " 'speake',\n",
       " 'neyther',\n",
       " 'begge',\n",
       " 'feare',\n",
       " 'fauors',\n",
       " 'hate',\n",
       " 'hayle',\n",
       " 'hayle',\n",
       " 'hayle',\n",
       " 'lesser',\n",
       " 'macbeth',\n",
       " 'greater',\n",
       " 'happy',\n",
       " 'yet',\n",
       " 'much',\n",
       " 'happyer',\n",
       " 'thou',\n",
       " 'shalt',\n",
       " 'get',\n",
       " 'king',\n",
       " 'though',\n",
       " 'thou',\n",
       " 'none',\n",
       " 'haile',\n",
       " 'macbeth',\n",
       " 'banquo',\n",
       " 'banquo',\n",
       " 'macbeth',\n",
       " 'haile',\n",
       " 'macb',\n",
       " 'stay',\n",
       " 'imperfect',\n",
       " 'speaker',\n",
       " 'tell',\n",
       " 'sinells',\n",
       " 'death',\n",
       " 'know',\n",
       " 'thane',\n",
       " 'glamis',\n",
       " 'cawdor',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'liues',\n",
       " 'prosperous',\n",
       " 'gentleman',\n",
       " 'king',\n",
       " 'stand',\n",
       " 'within',\n",
       " 'prospect',\n",
       " 'beleefe',\n",
       " 'cawdor',\n",
       " 'say',\n",
       " 'whence',\n",
       " 'owe',\n",
       " 'strange',\n",
       " 'intelligence',\n",
       " 'vpon',\n",
       " 'blasted',\n",
       " 'heath',\n",
       " 'stop',\n",
       " 'way',\n",
       " 'prophetique',\n",
       " 'greeting',\n",
       " 'speake',\n",
       " 'charge',\n",
       " 'witch',\n",
       " 'vanish',\n",
       " 'banq',\n",
       " 'earth',\n",
       " 'hath',\n",
       " 'bubble',\n",
       " 'water',\n",
       " 'ha',\n",
       " 'whither',\n",
       " 'vanish',\n",
       " 'macb',\n",
       " 'ayre',\n",
       " 'seem',\n",
       " 'corporall',\n",
       " 'melted',\n",
       " 'breath',\n",
       " 'winde',\n",
       " 'would',\n",
       " 'banq',\n",
       " 'thing',\n",
       " 'doe',\n",
       " 'speake',\n",
       " 'haue',\n",
       " 'eaten',\n",
       " 'insane',\n",
       " 'root',\n",
       " 'take',\n",
       " 'reason',\n",
       " 'prisoner',\n",
       " 'macb',\n",
       " 'child',\n",
       " 'shall',\n",
       " 'king',\n",
       " 'banq',\n",
       " 'shall',\n",
       " 'king',\n",
       " 'macb',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'went',\n",
       " 'banq',\n",
       " 'toth',\n",
       " 'tune',\n",
       " 'word',\n",
       " 'enter',\n",
       " 'rosse',\n",
       " 'angus',\n",
       " 'rosse',\n",
       " 'king',\n",
       " 'hath',\n",
       " 'happily',\n",
       " 'receiu',\n",
       " 'macbeth',\n",
       " 'newes',\n",
       " 'thy',\n",
       " 'successe',\n",
       " 'reades',\n",
       " 'thy',\n",
       " 'personall',\n",
       " 'venture',\n",
       " 'rebel',\n",
       " 'sight',\n",
       " 'wonder',\n",
       " 'prayses',\n",
       " 'doe',\n",
       " 'contend',\n",
       " 'thine',\n",
       " 'silenc',\n",
       " 'viewing',\n",
       " 'rest',\n",
       " 'day',\n",
       " 'findes',\n",
       " 'thee',\n",
       " 'stout',\n",
       " 'norweyan',\n",
       " 'rankes',\n",
       " 'nothing',\n",
       " 'afeard',\n",
       " 'thy',\n",
       " 'selfe',\n",
       " 'didst',\n",
       " 'make',\n",
       " 'strange',\n",
       " 'image',\n",
       " 'death',\n",
       " 'thick',\n",
       " 'tale',\n",
       " 'post',\n",
       " 'post',\n",
       " 'euery',\n",
       " 'one',\n",
       " 'beare',\n",
       " 'thy',\n",
       " 'prayses',\n",
       " 'kingdomes',\n",
       " 'great',\n",
       " 'defence',\n",
       " 'powr',\n",
       " 'downe',\n",
       " 'ang',\n",
       " 'wee',\n",
       " 'sent',\n",
       " 'giue',\n",
       " 'thee',\n",
       " 'royall',\n",
       " 'master',\n",
       " 'thanks',\n",
       " 'onely',\n",
       " 'harrold',\n",
       " 'thee',\n",
       " 'sight',\n",
       " 'pay',\n",
       " 'thee',\n",
       " 'rosse',\n",
       " 'earnest',\n",
       " 'greater',\n",
       " 'honor',\n",
       " 'bad',\n",
       " 'call',\n",
       " 'thee',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'addition',\n",
       " 'haile',\n",
       " 'worthy',\n",
       " 'thane',\n",
       " 'thine',\n",
       " 'banq',\n",
       " 'deuill',\n",
       " 'speake',\n",
       " 'true',\n",
       " 'macb',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'liues',\n",
       " 'doe',\n",
       " 'dresse',\n",
       " 'borrowed',\n",
       " 'robe',\n",
       " 'ang',\n",
       " 'thane',\n",
       " 'liues',\n",
       " 'yet',\n",
       " 'vnder',\n",
       " 'heauie',\n",
       " 'iudgement',\n",
       " 'beares',\n",
       " 'life',\n",
       " 'deserues',\n",
       " 'loose',\n",
       " 'whether',\n",
       " 'combin',\n",
       " 'norway',\n",
       " 'lyne',\n",
       " 'rebell',\n",
       " 'hidden',\n",
       " 'helpe',\n",
       " 'vantage',\n",
       " 'countreyes',\n",
       " 'wracke',\n",
       " 'know',\n",
       " 'treason',\n",
       " 'capitall',\n",
       " 'confess',\n",
       " 'prou',\n",
       " 'haue',\n",
       " 'ouerthrowne',\n",
       " 'macb',\n",
       " 'glamys',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'greatest',\n",
       " 'behinde',\n",
       " 'thankes',\n",
       " 'paine',\n",
       " 'doe',\n",
       " 'hope',\n",
       " 'child',\n",
       " 'shall',\n",
       " 'king',\n",
       " 'gaue',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'promis',\n",
       " 'lesse',\n",
       " 'banq',\n",
       " 'trusted',\n",
       " 'home',\n",
       " 'might',\n",
       " 'yet',\n",
       " 'enkindle',\n",
       " 'vnto',\n",
       " 'crowne',\n",
       " 'besides',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'strange',\n",
       " 'oftentimes',\n",
       " 'winne',\n",
       " 'v',\n",
       " 'harme',\n",
       " 'instrument',\n",
       " 'darknesse',\n",
       " 'tell',\n",
       " 'v',\n",
       " 'truth',\n",
       " 'winne',\n",
       " 'v',\n",
       " 'honest',\n",
       " 'trifle',\n",
       " 'deepest',\n",
       " 'consequence',\n",
       " 'cousin',\n",
       " 'word',\n",
       " 'pray',\n",
       " 'macb',\n",
       " 'two',\n",
       " 'truth',\n",
       " 'told',\n",
       " 'happy',\n",
       " 'prologue',\n",
       " 'swelling',\n",
       " 'act',\n",
       " 'imperiall',\n",
       " 'theame',\n",
       " 'thanke',\n",
       " 'gentleman',\n",
       " 'supernaturall',\n",
       " 'solliciting',\n",
       " 'ill',\n",
       " 'good',\n",
       " 'ill',\n",
       " 'hath',\n",
       " 'giuen',\n",
       " 'earnest',\n",
       " 'successe',\n",
       " 'commencing',\n",
       " 'truth',\n",
       " 'thane',\n",
       " 'cawdor',\n",
       " 'good',\n",
       " 'doe',\n",
       " 'yeeld',\n",
       " 'suggestion',\n",
       " 'whose',\n",
       " 'horrid',\n",
       " 'image',\n",
       " 'doth',\n",
       " 'vnfixe',\n",
       " 'heire',\n",
       " 'make',\n",
       " 'seated',\n",
       " 'heart',\n",
       " 'knock',\n",
       " 'ribbes',\n",
       " 'vse',\n",
       " 'nature',\n",
       " 'present',\n",
       " 'feares',\n",
       " 'lesse',\n",
       " 'horrible',\n",
       " 'imaginings',\n",
       " 'thought',\n",
       " 'whose',\n",
       " 'murther',\n",
       " 'yet',\n",
       " 'fantasticall',\n",
       " 'shake',\n",
       " 'single',\n",
       " 'state',\n",
       " 'man',\n",
       " 'function',\n",
       " 'smother',\n",
       " 'surmise',\n",
       " 'nothing',\n",
       " 'banq',\n",
       " 'looke',\n",
       " 'partner',\n",
       " 'rapt',\n",
       " 'macb',\n",
       " 'chance',\n",
       " 'haue',\n",
       " 'king',\n",
       " 'chance',\n",
       " 'may',\n",
       " 'crowne',\n",
       " 'without',\n",
       " 'stirre',\n",
       " 'banq',\n",
       " 'new',\n",
       " 'honor',\n",
       " 'come',\n",
       " 'vpon',\n",
       " 'like',\n",
       " 'strange',\n",
       " 'garment',\n",
       " 'cleaue',\n",
       " 'mould',\n",
       " 'aid',\n",
       " 'vse',\n",
       " 'macb',\n",
       " 'come',\n",
       " 'come',\n",
       " 'may',\n",
       " 'time',\n",
       " 'houre',\n",
       " 'run',\n",
       " 'roughest',\n",
       " 'day',\n",
       " 'banq',\n",
       " 'worthy',\n",
       " 'macbeth',\n",
       " 'wee',\n",
       " 'stay',\n",
       " 'vpon',\n",
       " 'leysure',\n",
       " 'macb',\n",
       " 'giue',\n",
       " 'fauour',\n",
       " 'dull',\n",
       " 'braine',\n",
       " 'wrought',\n",
       " 'thing',\n",
       " 'forgotten',\n",
       " 'kinde',\n",
       " 'gentleman',\n",
       " 'paine',\n",
       " 'registred',\n",
       " 'euery',\n",
       " 'day',\n",
       " 'turne',\n",
       " 'leafe',\n",
       " 'reade',\n",
       " 'let',\n",
       " 'v',\n",
       " 'toward',\n",
       " 'king',\n",
       " 'thinke',\n",
       " 'vpon',\n",
       " ...]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_text['shakespeare-macbeth.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define n\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating n-grams from tokenised text\n",
    "#creating unigram, bigrams, trigtams from tokens\n",
    "\n",
    "#can also use ntlk.ngrams()\n",
    "\n",
    "def create_ngrams(tokens, n):\n",
    "    n_gram_tokens = []\n",
    "    for i in range(len(tokens)-n):\n",
    "        n_gram_tokens.append(tuple(tokens[i:i+n]))\n",
    "    return n_gram_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emma', 'jane', 'austen'),\n",
       " ('jane', 'austen', 'volume'),\n",
       " ('austen', 'volume', 'chapter'),\n",
       " ('volume', 'chapter', 'emma'),\n",
       " ('chapter', 'emma', 'woodhouse'),\n",
       " ('emma', 'woodhouse', 'handsome')]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#second part - calcualte frequency\n",
    "sample = file_text['austen-emma.txt']\n",
    "ngrams_sample = create_ngrams(sample,n)\n",
    "ngrams_sample[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "ngram_frequency = Counter([tuple(ngram) for ngram in ngrams_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the probability of a word following a given n-1 gram\n",
    "\n",
    "def probability_helper(sample,n):\n",
    "    \"\"\"\n",
    "    sample: text sample\n",
    "    n: n-gram size\n",
    "    return: dataframe with probability\n",
    "    \"\"\"\n",
    "    #get ngrams\n",
    "    ngrams_sample = create_ngrams(sample,n)\n",
    "\n",
    "    #get frequency\n",
    "    ngram_frequency = Counter([tuple(ngram) for ngram in ngrams_sample])\n",
    "\n",
    "    #ger probability\n",
    "    df = pd.DataFrame.from_dict(ngram_frequency, orient='index').reset_index()\n",
    "    df.columns = ['sequence',  'count']\n",
    "\n",
    "    #convert first column into 2 columns where first column has n-1 words, the second column has nth word\n",
    "    df['nth_word'] = df['sequence'].apply(lambda x: x[-1])\n",
    "\n",
    "    def get_sequence(tuple):\n",
    "        x = ''\n",
    "        for i in range(len(tuple)-1):\n",
    "            x+=(tuple[i])\n",
    "            x+=','\n",
    "        x = x[:-1]\n",
    "        x = x.replace(\",\",\" \")\n",
    "        return x\n",
    "\n",
    "    df['sequence'] = df['sequence'].apply(lambda x: get_sequence(x))\n",
    "\n",
    "    #get ids for sequences and predictions\n",
    "    df_sorted = df.sort_values(by='sequence')\n",
    "    df_sorted['sequence_id'] = range(1, len(df_sorted) + 1)\n",
    "    df_new = df_sorted\n",
    "    df_sorted = df_new.sort_values(by='nth_word')\n",
    "    df_sorted['prediction_id'] = range(1, len(df_sorted) + 1)\n",
    "\n",
    "    return df, df_sorted\n",
    "\n",
    "def get_probability(sample,n,type = None):\n",
    "    if type==None:\n",
    "\n",
    "        df, df_sorted = probability_helper(sample,n)\n",
    "        totals = df.groupby('sequence')['count'].sum().reset_index().rename(columns={'count':'total'})\n",
    "        df_sorted = df_sorted.merge(totals, how = 'left', on = 'sequence')\n",
    "        df_sorted['probability'] = df_sorted['count']/df_sorted['total']\n",
    "    elif type ==\"smooth\":\n",
    "        df, df_sorted = probability_helper(sample,n)\n",
    "        v = df_sorted['prediction_id'].max()\n",
    "        \n",
    "        totals = df.groupby('sequence')['count'].sum().reset_index().rename(columns={'count':'total'})\n",
    "        df_sorted = df_sorted.merge(totals, how = 'left', on = 'sequence')\n",
    "        df_sorted['probability'] = (df_sorted['count']+1)/(df_sorted['total'] + v)\n",
    "\n",
    "    return df_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>count</th>\n",
       "      <th>nth_word</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>total</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hartfield donwell</td>\n",
       "      <td>1</td>\n",
       "      <td>abbey</td>\n",
       "      <td>26150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>secondary donwell</td>\n",
       "      <td>1</td>\n",
       "      <td>abbey</td>\n",
       "      <td>51925</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owner donwell</td>\n",
       "      <td>1</td>\n",
       "      <td>abbey</td>\n",
       "      <td>43409</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sheltered rose</td>\n",
       "      <td>1</td>\n",
       "      <td>abbey</td>\n",
       "      <td>53402</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>belonging haunting</td>\n",
       "      <td>1</td>\n",
       "      <td>abbey</td>\n",
       "      <td>5026</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68560</th>\n",
       "      <td>drawing much</td>\n",
       "      <td>1</td>\n",
       "      <td>zeal</td>\n",
       "      <td>14600</td>\n",
       "      <td>68561</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68561</th>\n",
       "      <td>watched safely</td>\n",
       "      <td>1</td>\n",
       "      <td>zeal</td>\n",
       "      <td>63949</td>\n",
       "      <td>68562</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68562</th>\n",
       "      <td>idea greatest</td>\n",
       "      <td>1</td>\n",
       "      <td>zeal</td>\n",
       "      <td>28227</td>\n",
       "      <td>68563</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68563</th>\n",
       "      <td>shall try</td>\n",
       "      <td>1</td>\n",
       "      <td>zeal</td>\n",
       "      <td>53327</td>\n",
       "      <td>68564</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68564</th>\n",
       "      <td>room little</td>\n",
       "      <td>1</td>\n",
       "      <td>zigzag</td>\n",
       "      <td>50297</td>\n",
       "      <td>68565</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68565 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sequence  count nth_word  sequence_id  prediction_id  total  \\\n",
       "0       hartfield donwell      1    abbey        26150              1      1   \n",
       "1       secondary donwell      1    abbey        51925              2      1   \n",
       "2           owner donwell      1    abbey        43409              3      1   \n",
       "3          sheltered rose      1    abbey        53402              4      1   \n",
       "4      belonging haunting      1    abbey         5026              5      1   \n",
       "...                   ...    ...      ...          ...            ...    ...   \n",
       "68560        drawing much      1     zeal        14600          68561      1   \n",
       "68561      watched safely      1     zeal        63949          68562      1   \n",
       "68562       idea greatest      1     zeal        28227          68563      1   \n",
       "68563           shall try      1     zeal        53327          68564      3   \n",
       "68564         room little      1   zigzag        50297          68565      1   \n",
       "\n",
       "       probability  \n",
       "0         1.000000  \n",
       "1         1.000000  \n",
       "2         1.000000  \n",
       "3         1.000000  \n",
       "4         1.000000  \n",
       "...            ...  \n",
       "68560     1.000000  \n",
       "68561     1.000000  \n",
       "68562     1.000000  \n",
       "68563     0.333333  \n",
       "68564     1.000000  \n",
       "\n",
       "[68565 rows x 7 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs  = get_probability(sample, n)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>count</th>\n",
       "      <th>nth_word</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>total</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25852</th>\n",
       "      <td>shall try</td>\n",
       "      <td>1</td>\n",
       "      <td>harriet</td>\n",
       "      <td>53328</td>\n",
       "      <td>25853</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44906</th>\n",
       "      <td>shall try</td>\n",
       "      <td>1</td>\n",
       "      <td>persuade</td>\n",
       "      <td>53329</td>\n",
       "      <td>44907</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68563</th>\n",
       "      <td>shall try</td>\n",
       "      <td>1</td>\n",
       "      <td>zeal</td>\n",
       "      <td>53327</td>\n",
       "      <td>68564</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sequence  count  nth_word  sequence_id  prediction_id  total  \\\n",
       "25852  shall try      1   harriet        53328          25853      3   \n",
       "44906  shall try      1  persuade        53329          44907      3   \n",
       "68563  shall try      1      zeal        53327          68564      3   \n",
       "\n",
       "       probability  \n",
       "25852     0.333333  \n",
       "44906     0.333333  \n",
       "68563     0.333333  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[probs['sequence']=='shall try']\n",
    "#incorporate randomness when probability is equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sorted.pivot(index = ['sequence_id'], columns = ['prediction_id'], values = 'count')\n",
    "#creating an array was too big\n",
    "#so we will get totals and get a probaility by a simple divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbey\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Write a function to predict the next word given the sequence of words\n",
    "def predict(data, sequence):\n",
    "    \"\"\"this function generates predictions based on probabilities seen in the dataset\"\"\"\n",
    "    try:\n",
    "        subset = data[data['sequence']==sequence.strip()]\n",
    "        result = subset.iloc[subset['probability'].argmax()]['nth_word'] #return the word with max probability\n",
    "        #print(\"sequence detected\")\n",
    "        return result\n",
    "    except:\n",
    "        result = random.choice(data['nth_word'].unique())\n",
    "        #print(\"sequence not detected\")\n",
    "        return result\n",
    "    #test\n",
    "\n",
    "print(predict(probs,'secondary donwell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence number 1: secondary donwell\n",
      "sequence detected\n",
      "sequence number 2: donwell abbey\n",
      "sequence detected\n",
      "sequence number 3: abbey chapter\n",
      "sequence detected\n",
      "sequence number 4: chapter vi\n",
      "sequence detected\n",
      "sequence number 5: vi emma\n",
      "sequence detected\n",
      "secondary donwell abbey chapter vi emma could\n"
     ]
    }
   ],
   "source": [
    "#Write a function to generate a sentence of a specified length given a prefix of (n−1) words\n",
    "\n",
    "def generate_sentence(data, sequence, n,len ):\n",
    "    \"\"\"\n",
    "    data: result of get_probability()\n",
    "    sequence: should be n-1 words together\n",
    "    len: number of predictions to be made\n",
    "    \"\"\"\n",
    "    sentence = sequence\n",
    "    sentence = sentence.strip()\n",
    "    for i in range(len):\n",
    "        n_minus_1_sequence = ' '.join(sentence.split(\" \")[-n+1:])\n",
    "        print(f'sequence number {i+1}: {n_minus_1_sequence}')\n",
    "        next_word = predict(data, n_minus_1_sequence)\n",
    "        sentence = sentence + ' ' + next_word\n",
    "    return sentence\n",
    "    \n",
    "result = generate_sentence(probs, \"secondary donwell\", 3,5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement smoothing techniques (like Laplace smoothing) to handle the issues of zero probabilities for unseen n-grams.\n",
    "#Updating the probability function to incorporate laplac smoothing\n",
    "def get_probability(sample,n,type = None):\n",
    "    if type==None:\n",
    "        df, df_sorted = probability_helper(sample,n)\n",
    "        totals = df.groupby('sequence')['count'].sum().reset_index().rename(columns={'count':'total'})\n",
    "        df_sorted = df_sorted.merge(totals, how = 'left', on = 'sequence')\n",
    "        df_sorted['probability'] = df_sorted['count']/df_sorted['total']\n",
    "\n",
    "    elif type ==\"smooth\":\n",
    "        df, df_sorted = probability_helper(sample,n)\n",
    "        v = df_sorted['prediction_id'].max()\n",
    "        totals = df.groupby('sequence')['count'].sum().reset_index().rename(columns={'count':'total'})\n",
    "        df_sorted = df_sorted.merge(totals, how = 'left', on = 'sequence')\n",
    "        df_sorted['probability'] = (df_sorted['count']+1)/(df_sorted['total'] + v)\n",
    "\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does not exist\n",
      "does not exist\n",
      "does not exist\n",
      "does not exist\n",
      "does not exist\n",
      "secondary something sensibility educate insufficient received among\n"
     ]
    }
   ],
   "source": [
    "#to show a demonstration of this, we need to get probabilities for laplace smoothing and send in a sequence that is not existing in the dataset\n",
    "probs_smooth = get_probability(sample, n,type = \"smooth\")\n",
    "result = generate_sentence(probs_smooth, \"secondary something\", 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that for n-grams when n is 3:\n",
    "\n",
    "the first sequence: \"secondary something\" does not exist in the dataset, \n",
    "\n",
    "second sequence: \"something sensibility\" does not exist either and \n",
    "\n",
    "similarly, \"sensibility educate\", \"educate insufficient\"... dont exist in the dataset and yet we are able to generate predictions using Laplace Smoothing in the PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3 Test the model with different (n − 1)-gram inputs to see how it predicts the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def preprocess_new(text):\n",
    "    \n",
    "    #Tokenize lowercase, and remove stop words\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Remove punctuation from the list of tokens\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return tokens\n",
    "    \n",
    "files = gutenberg.fileids()\n",
    "text = [gutenberg.raw(fileid) for fileid in gutenberg.fileids()]\n",
    "file_text = dict(zip(files, text))\n",
    "\n",
    "for key, value in file_text.items():\n",
    "    file_text[key] = preprocess_new(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence number 1: what\n",
      "sequence number 2: caterpillar\n",
      "sequence number 3: fly\n",
      "sequence number 4: feed\n",
      "sequence number 5: little\n",
      "what caterpillar fly feed little boy\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "test_file = file_text['blake-poems.txt']\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "result = generate_sentence(probs_test, \"what  \",n, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence number 1: caterpillar\n",
      "sequence number 2: fly\n",
      "sequence number 3: feed\n",
      "sequence number 4: little\n",
      "sequence number 5: boy\n",
      "caterpillar fly feed little boy lost\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "test_file = file_text['blake-poems.txt']\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "result = generate_sentence(probs_test, \"caterpillar  \",n, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence number 1: blight plague\n",
      "sequence number 2: plague human\n",
      "sequence number 3: human abstract\n",
      "sequence number 4: abstract pity\n",
      "sequence number 5: pity would\n",
      "blight plague human abstract pity would make\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "test_file = file_text['blake-poems.txt']\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "result = generate_sentence(probs_test, \"blight plague\",n, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence number 1: blight plague human\n",
      "sequence number 2: plague human abstract\n",
      "sequence number 3: human abstract pity\n",
      "sequence number 4: abstract pity would\n",
      "sequence number 5: pity would make\n",
      "blight plague human abstract pity would make somebody\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "test_file = file_text['blake-poems.txt']\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "result = generate_sentence(probs_test, \"blight plague human \",n, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence number 1: blight plague human is\n",
      "sequence number 2: plague human is shriek\n",
      "sequence number 3: human is shriek nostril\n",
      "sequence number 4: is shriek nostril fallen\n",
      "sequence number 5: shriek nostril fallen frame\n",
      "blight plague human is shriek nostril fallen frame end\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "test_file = file_text['blake-poems.txt']\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "result = generate_sentence(probs_test, \"blight plague human is \",n, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1675.4673943165446\n"
     ]
    }
   ],
   "source": [
    "#Compare the performance of different n values (e.g., bigrams vs. trigrams)\n",
    "\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "probs_test['log_probability'] = np.log(probs_test['probability'])\n",
    "# Sum of log probabilities\n",
    "sum_log_prob = probs_test['log_probability'].sum()\n",
    "# Number of predictions\n",
    "N = len(probs_test)\n",
    "# Calculate perplexity\n",
    "perplexity = np.exp(-sum_log_prob / N)\n",
    "\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1813.0033448299969\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "probs_test['log_probability'] = np.log(probs_test['probability'])\n",
    "# Sum of log probabilities\n",
    "sum_log_prob = probs_test['log_probability'].sum()\n",
    "# Number of predictions\n",
    "N = len(probs_test)\n",
    "# Calculate perplexity\n",
    "perplexity = np.exp(-sum_log_prob / N)\n",
    "\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1842.8593390221017\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "probs_test['log_probability'] = np.log(probs_test['probability'])\n",
    "# Sum of log probabilities\n",
    "sum_log_prob = probs_test['log_probability'].sum()\n",
    "# Number of predictions\n",
    "N = len(probs_test)\n",
    "# Calculate perplexity\n",
    "perplexity = np.exp(-sum_log_prob / N)\n",
    "\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1852.0622740820113\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "probs_test  = get_probability(test_file, n,type = \"smooth\")\n",
    "probs_test['log_probability'] = np.log(probs_test['probability'])\n",
    "# Sum of log probabilities\n",
    "sum_log_prob = probs_test['log_probability'].sum()\n",
    "# Number of predictions\n",
    "N = len(probs_test)\n",
    "# Calculate perplexity\n",
    "perplexity = np.exp(-sum_log_prob / N)\n",
    "\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is a measure of uncertainty or \"surprise\" of a language model. A lower perplexity indicates that the language model is more confident in its predictions (i.e., less surprised by the test data). This typically means the model is more accurate in predicting the probability of a sequence of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Short Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this short notebook, we defined various functions that helped us achieve tasks necessary to build an n-gram model i.e.\n",
    "1. preprocess text \n",
    "2. derive n-grams\n",
    "3. calculate frequency/count\n",
    "4. calculate probability to define PDFs\n",
    "5. Use PDFs to predict words\n",
    "\n",
    "In the end we run examples to predict sentences from an initial sequence for different n-gram models. We saw that as n increases, the likelihood of the model, encountering a 'never-seen-before' sequence also increases. In other words, the model can be more 'perplexed' at the sequence it sees.\n",
    "\n",
    "#### Perplexity in n-gram models:\n",
    "Increasing the 'n' in an n-gram model generally makes the model more powerful because it can capture longer dependencies. However, this does not always lead to lower perplexity. The impact on perplexity can depend on various factors, such as the amount and representativeness of the training data, and the handling of unseen n-grams.\n",
    "\n",
    "With a higher 'n', the model becomes more specific, potentially leading to better performance on similar types of data as seen during training. However, it might also lead to increased sparsity and overfitting, especially if the training data is not sufficiently large and diverse.\n",
    "\n",
    "The model might become too sensitive to the specific training data and fail to generalize well to new, unseen data, which can actually increase perplexity. This is particularly true for rare n-grams that do not appear often in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, while a more complex model (with a higher 'n' in an n-gram model) might theoretically be more powerful, in practice, its effectiveness and impact on perplexity depend on factors like data availability, overfitting, and how well it can generalize beyond the training data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('smoothenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccbb5ec2d2a75591ebe5fca0a133e85ca5a4057852e563373f3397512e082f6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
